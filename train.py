import torch
import pandas as pd
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from transformers import BlipProcessor, BlipForQuestionAnswering, AdamW
from tqdm import tqdm
import os

# --- ì„¤ì • ---
TRAIN_DATA_PATH = './data/train.csv'
SAVED_MODEL_PATH = './saved_model'
MODEL_NAME = 'Salesforce/blip-vqa-large'
NUM_EPOCHS = 5  # í•™ìŠµ íšŸìˆ˜ (ì—í­)
BATCH_SIZE = 4  # í•œ ë²ˆì— ì²˜ë¦¬í•  ë°ì´í„° ìˆ˜
LEARNING_RATE = 5e-6 # í•™ìŠµë¥ 

# --- ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ---
class VQADataset(Dataset):
    def __init__(self, df, processor, img_base_path):
        self.df = df
        self.processor = processor
        self.img_base_path = img_base_path

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = os.path.join(self.img_base_path, os.path.basename(row['img_path']))
        question = row['Question']
        
        # ì •ë‹µ í…ìŠ¤íŠ¸ ìƒì„± (A, B, C, D ì¤‘ ì •ë‹µì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©)
        answer_letter = row['answer']
        answer_text = row[answer_letter]

        try:
            image = Image.open(img_path).convert('RGB')
        except FileNotFoundError:
            print(f"Warning: File not found {img_path}, skipping.")
            return None

        # VQA ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ ì´ë¯¸ì§€, ì§ˆë¬¸, ë‹µë³€ì„ ëª¨ë‘ ì¸ì½”ë”©
        encoding = self.processor(image, question, text=answer_text, padding="max_length", truncation=True, return_tensors="pt")
        
        # ë¶ˆí•„ìš”í•œ ì°¨ì› ì œê±°
        encoding = {k: v.squeeze() for k, v in encoding.items()}
        return encoding

# --- ë©”ì¸ í•™ìŠµ í•¨ìˆ˜ ---
def main():
    # ì¥ì¹˜ ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ Using device: {device}")

    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ê¸° ì¤€ë¹„
    train_df = pd.read_csv(TRAIN_DATA_PATH)
    processor = BlipProcessor.from_pretrained(MODEL_NAME)
    
    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
    # train_input_images í´ë” ê²½ë¡œë¥¼ ì •í™•íˆ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    img_base_path = os.path.dirname(train_df['img_path'][0])
    train_dataset = VQADataset(train_df, processor, img_base_path)
    
    # None ê°’ì„ í•„í„°ë§í•˜ê¸° ìœ„í•œ collate_fn
    def collate_fn(batch):
        batch = [item for item in batch if item is not None]
        if not batch:
            return None, None
        return torch.utils.data.dataloader.default_collate(batch)

    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)

    # ëª¨ë¸ ë¡œë“œ ë° ìµœì í™” ì„¤ì •
    model = BlipForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)
    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)

    print("âœ… Setup complete. Starting training...")

    # í•™ìŠµ ë£¨í”„
    model.train()
    for epoch in range(NUM_EPOCHS):
        print(f"\n--- Epoch {epoch+1}/{NUM_EPOCHS} ---")
        total_loss = 0
        
        for batch in tqdm(train_dataloader, desc=f"Training Epoch {epoch+1}"):
            if batch is None:
                continue

            input_ids = batch['input_ids'].to(device)
            pixel_values = batch['pixel_values'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            optimizer.zero_grad()
            
            # ëª¨ë¸ ì¶œë ¥ ë° ì†ì‹¤ ê³„ì‚°
            outputs = model(input_ids=input_ids,
                              pixel_values=pixel_values,
                              attention_mask=attention_mask,
                              labels=labels)
            
            loss = outputs.loss
            
            # ì—­ì „íŒŒ ë° ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()

        avg_loss = total_loss / len(train_dataloader)
        print(f"Epoch {epoch+1} Average Loss: {avg_loss:.4f}")

    # í•™ìŠµëœ ëª¨ë¸ ì €ì¥
    if not os.path.exists(SAVED_MODEL_PATH):
        os.makedirs(SAVED_MODEL_PATH)
        
    model.save_pretrained(SAVED_MODEL_PATH)
    processor.save_pretrained(SAVED_MODEL_PATH)
    print(f"ğŸ‰ Model successfully saved to {SAVED_MODEL_PATH}")

if __name__ == '__main__':
    main()